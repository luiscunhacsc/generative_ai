{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "428e9e19",
   "metadata": {},
   "source": [
    "\n",
    "Credits:\n",
    "Copyright 2023 David Foster.\n",
    "Foster, D. (2023). Generative deep learning (2nd Ed). O'Reilly.\n",
    "\n",
    "Slightly modified by LuÃ­s SimÃµes da Cunha, 2023: mainly to readily run in Google Colab and/or pedagogical reasons.\n",
    "\n",
    "Original repository [retrivable here](https://github.com/davidADSP/Generative_Deep_Learning_2nd_Edition)\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at https://www.apache.org/licenses/LICENSE-2.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d0f234",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def sample_batch(dataset):\n",
    "    batch = dataset.take(1).get_single_element()\n",
    "    if isinstance(batch, tuple):\n",
    "        batch = batch[0]\n",
    "    return batch.numpy()\n",
    "\n",
    "def display(\n",
    "    images, n=10, size=(20, 3), cmap=\"gray_r\", as_type=\"float32\", save_to=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Displays n random images from each one of the supplied arrays.\n",
    "    \"\"\"\n",
    "    if images.max() > 1.0:\n",
    "        images = images / 255.0\n",
    "    elif images.min() < 0.0:\n",
    "        images = (images + 1.0) / 2.0\n",
    "\n",
    "    plt.figure(figsize=size)\n",
    "    for i in range(n):\n",
    "        _ = plt.subplot(1, n, i + 1)\n",
    "        plt.imshow(images[i].astype(as_type), cmap=cmap)\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "    if save_to:\n",
    "        plt.savefig(save_to)\n",
    "        print(f\"\\nSaved to {save_to}\")\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸž Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we'll walk through the steps required to train your own convolutional neural network (CNN) on the CIFAR dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'notebooks'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\FosterGenAI\\Generative_Deep_Learning_2nd_Edition-main\\notebooks\\02_deeplearning\\02_cnn\\cnn.ipynb Cell 3\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/FosterGenAI/Generative_Deep_Learning_2nd_Edition-main/notebooks/02_deeplearning/02_cnn/cnn.ipynb#W2sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/FosterGenAI/Generative_Deep_Learning_2nd_Edition-main/notebooks/02_deeplearning/02_cnn/cnn.ipynb#W2sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m layers, models, optimizers, utils, datasets\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/FosterGenAI/Generative_Deep_Learning_2nd_Edition-main/notebooks/02_deeplearning/02_cnn/cnn.ipynb#W2sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mnotebooks\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m display\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'notebooks'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras import layers, models, optimizers, utils, datasets\n",
    "# from notebooks.utils import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 0. Parameters <a name=\"parameters\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prepare the Data <a name=\"prepare\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype(\"float32\") / 255.0\n",
    "x_test = x_test.astype(\"float32\") / 255.0\n",
    "\n",
    "y_train = utils.to_categorical(y_train, NUM_CLASSES)\n",
    "y_test = utils.to_categorical(y_test, NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(x_train[:10])\n",
    "print(y_train[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build the model <a name=\"build\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = layers.Input((32, 32, 3))\n",
    "\n",
    "x = layers.Conv2D(filters=32, kernel_size=3, strides=1, padding=\"same\")(\n",
    "    input_layer\n",
    ")\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "\n",
    "x = layers.Conv2D(filters=32, kernel_size=3, strides=2, padding=\"same\")(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "\n",
    "x = layers.Conv2D(filters=64, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "\n",
    "x = layers.Conv2D(filters=64, kernel_size=3, strides=2, padding=\"same\")(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "\n",
    "x = layers.Flatten()(x)\n",
    "\n",
    "x = layers.Dense(128)(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.Dropout(rate=0.5)(x)\n",
    "\n",
    "x = layers.Dense(NUM_CLASSES)(x)\n",
    "output_layer = layers.Activation(\"softmax\")(x)\n",
    "\n",
    "model = models.Model(input_layer, output_layer)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3. Train the model <a name=\"train\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optimizers.Adam(learning_rate=0.0005)\n",
    "model.compile(\n",
    "    loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=32,\n",
    "    epochs=10,\n",
    "    shuffle=True,\n",
    "    validation_data=(x_test, y_test),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 4. Evaluation <a name=\"evaluate\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x_test, y_test, batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES = np.array(\n",
    "    [\n",
    "        \"airplane\",\n",
    "        \"automobile\",\n",
    "        \"bird\",\n",
    "        \"cat\",\n",
    "        \"deer\",\n",
    "        \"dog\",\n",
    "        \"frog\",\n",
    "        \"horse\",\n",
    "        \"ship\",\n",
    "        \"truck\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "preds = model.predict(x_test)\n",
    "preds_single = CLASSES[np.argmax(preds, axis=-1)]\n",
    "actual_single = CLASSES[np.argmax(y_test, axis=-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n_to_show = 10\n",
    "indices = np.random.choice(range(len(x_test)), n_to_show)\n",
    "\n",
    "fig = plt.figure(figsize=(15, 3))\n",
    "fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "\n",
    "for i, idx in enumerate(indices):\n",
    "    img = x_test[idx]\n",
    "    ax = fig.add_subplot(1, n_to_show, i + 1)\n",
    "    ax.axis(\"off\")\n",
    "    ax.text(\n",
    "        0.5,\n",
    "        -0.35,\n",
    "        \"pred = \" + str(preds_single[idx]),\n",
    "        fontsize=10,\n",
    "        ha=\"center\",\n",
    "        transform=ax.transAxes,\n",
    "    )\n",
    "    ax.text(\n",
    "        0.5,\n",
    "        -0.7,\n",
    "        \"act = \" + str(actual_single[idx]),\n",
    "        fontsize=10,\n",
    "        ha=\"center\",\n",
    "        transform=ax.transAxes,\n",
    "    )\n",
    "    ax.imshow(img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
